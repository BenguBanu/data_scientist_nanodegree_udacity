{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "## Gaussian Mixture Models\n",
    "##### Elliot Partridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Model \n",
    "Assumes that each cluster follows a certain statistical distribution\n",
    "\n",
    "### Gaussian Clustering in One Dimension\n",
    "Creates multiple overlapping gaussian distributions to create seperate clusters within one dataset\n",
    "\n",
    "### Gaussian Clustering in Two Dimensions\n",
    "One visual way to look at a multivariate gaussian distributed dataset is via concentric cirlces for the two axes where the center cirlce contains 68% of the data, 2nd 95 etc.\n",
    "\n",
    "#### Expectation Maximization Algo\n",
    "1. Initialise the gaussian distirbutions (set mean and variance for each dist)\n",
    "2. Expectation step: soft clustering of the dataset, provides a probability of belonging to either cluster\n",
    "3. Maximisation Step: Take memberships from above to come up for new parameters for the gaussians (set mean and variance for each dist)\n",
    "4. Evaluate log-likelihood: calculate how well the model we have created fits the data. We want to maximise this value by adjusting parameters to reach convergence\n",
    "\n",
    "**Advantages:**\n",
    "- Soft-clustering (multiple categories / topics)\n",
    "- Cluster shape flexibility\n",
    "\n",
    "**Disadvantages:**\n",
    "- Sensitive to initialisation values\n",
    "- Possible to converge to local optimum\n",
    "- Slow convergence rate\n",
    "\n",
    "[Example sensor-detection paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.681.3152&rep=rep1&type=pdf)\n",
    "[example background paper](http://www.ai.mit.edu/projects/vsam/Publications/stauffer_cvpr98_track.pdf)\n",
    "\n",
    "### Clustering Process\n",
    "\n",
    "1. Feature selection\n",
    "2. Feature extraction\n",
    "3. Choose clustering algorithm, proximity measure\n",
    "4. Clustering validation (visual, scoring methods: clustering validation index)\n",
    "\n",
    "#### Cluster Validation\n",
    "1. **External indices**: used if the data was originally labeled\n",
    "2. **Internal indices**: used if the data wasn't orginally labeled\n",
    "3. **relative indices**:\n",
    "\n",
    "**Validation indices are defined by**:\n",
    "- **Compactness:** how compact clusters are together\n",
    "- **Separability:** how far distinct clusters are away from each other\n",
    "\n",
    "##### External Validation Indices\n",
    "- **Adjusted Rand Index**\n",
    "\n",
    "##### Internal Validation Indices\n",
    "- **Silhouette Coefficient:** _Shouldn't be used with DBSCAN since it has no concept of noise. Doesn't work so well with 'double o' datasets (use DBCV)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
